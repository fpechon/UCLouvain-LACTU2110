---
title: An R Markdown document converted from "5. GLM/Elastic Net.ipynb"
output: html_document
---

```{r}
# The easiest way to get recipes is to install all of tidymodels:
# install.packages("tidymodels")
install.packages("multilevelmod")
options(encoding = 'UTF-8')
#Loading all the necessary packages
if (!require("caret")) install.packages("caret")
if (!require("recipes")) install.packages("recipes")
if (!require("visreg")) install.packages("visreg")
if (!require("MASS")) install.packages("MASS")
if (!require("glmnet")) install.packages("glmnet")
if (!require("jtools")) install.packages("jtools")
if (!require("scales")) install.packages("scales")
if (!require("forcats")) install.packages("forcats")
if (!require("stringr")) install.packages("stringr")
if (!require("poissonreg")) install.packages("poissonreg")



require("caret")
require("recipes")
require("visreg")
require("MASS")
require("glmnet")
require("jtools")
require("scales")
require("forcats")
require("stringr")
require("arrow")
require("forcats")
require("doParallel")
require("yardstick")
require("parsnip")
require("workflows")
require("poissonreg")
require("rsample")
require("tune")
require("yardstick")

options(repr.plot.width = 8, repr.plot.height = 6, repr.plot.res = 150);
```

```{r}
dataset = read_parquet(file = "../data/dataset.parquet")

set.seed(21)
in_training = createDataPartition(dataset$ClaimNb, times = 1, p = 0.8, list = FALSE)
training_set = dataset[in_training, ]
testing_set = dataset[-in_training, ]
```

# Lasso 

```{r}
ptn=Sys.time()
x = model.matrix(ClaimNb ~ 0 + Power  * Region + Power*Brand + Power*Gas +  Region* Brand + Region* Gas + Brand*Gas,
                 data=training_set)
set.seed(542)
folds = createFolds(training_set$ClaimNb, 5, list=FALSE)

set.seed(58)
m.lasso.0.cv = cv.glmnet(x, y = training_set$ClaimNb, 
                         offset = log(training_set$Exposure),
       family = "poisson",
       alpha = 1, #LASSO = 1, Ridge = 0,
       nfolds = 5,
       foldid = folds,
       maxit=10^4,
       nlambda = 25)


ptn_1 = Sys.time() - ptn
ptn_1
```

```{r}
plot(m.lasso.0.cv)
```

```{r}
coef(m.lasso.0.cv, s = "lambda.min")
```

# Ridge

```{r}
ptn=Sys.time()
set.seed(58)
m.ridge.0.cv = cv.glmnet(x, y = training_set$ClaimNb, offset = log(training_set$Exposure),
       family = "poisson",
       alpha = 0, #LASSO = 1, Ridge = 0,
       nfolds = 5,
       foldid = folds,
       maxit = 10^3,
       nlambda = 25)

ptn_1 = Sys.time() - ptn
ptn_1
```

```{r}
plot(m.ridge.0.cv)
```

# Elastic Net

```{r}
ptn=Sys.time()
set.seed(58)
m.elasticnet.0.cv = cv.glmnet(x, y = training_set$ClaimNb, offset = log(training_set$Exposure),
       family = "poisson",
       alpha = 0.5, #LASSO = 1, Ridge = 0,
       nfolds = 5,
       foldid = folds,
       maxit = 10^3,
       nlambda = 25)

ptn_1 = Sys.time() - ptn
ptn_1
```

```{r}
plot(m.elasticnet.0.cv)
```

# Comparison with GLM

```{r}
x_test = model.matrix(ClaimNb ~ 0 + Power * Region + Power * Brand + Power * Gas +
    Region * Brand + Region * Gas + Brand * Gas, data = testing_set)


2 * (sum(dpois(x = testing_set$ClaimNb, lambda = testing_set$ClaimNb, log = TRUE)) -
    sum(dpois(x = testing_set$ClaimNb, lambda = predict(m.lasso.0.cv, newx = x_test,
        newoffset = log(testing_set$Exposure), s = m.lasso.0.cv$lambda.min, type = "response"),
        log = TRUE)))
```

```{r}
2 * (sum(dpois(x = testing_set$ClaimNb, lambda = testing_set$ClaimNb, log = TRUE)) -
    sum(dpois(x = testing_set$ClaimNb, lambda = predict(m.ridge.0.cv, newx = x_test,
        newoffset = log(testing_set$Exposure), s = m.ridge.0.cv$lambda.min, type = "response"),
        log = TRUE)))
```

```{r}
2 * (sum(dpois(x = testing_set$ClaimNb, lambda = testing_set$ClaimNb, log = TRUE)) -
    sum(dpois(x = testing_set$ClaimNb, lambda = predict(m.elasticnet.0.cv, newx = x_test,
        newoffset = log(testing_set$Exposure), s = m.elasticnet.0.cv$lambda.min,
        type = "response"), log = TRUE)))
```

# Experiment

Let us construct the factors a bit differently. We will only use the variables DriverAge and CarAge for illustration here.

```{r}
driver_age_lst = c()
for (age in (18:99)){
    training_set[paste0("DriverAge_", age)] = 1*(training_set$DriverAge <= age)
    testing_set[paste0("DriverAge_", age)] = 1*(testing_set$DriverAge <= age)
    driver_age_lst = c(driver_age_lst, paste0("DriverAge_", age))
}

car_age_lst = c()
for (vehage in (0:25)){
    training_set[paste0("CarAge_", vehage)] = 1*(training_set$CarAge <= vehage)
    testing_set[paste0("CarAge_", vehage)] = 1*(testing_set$CarAge <= vehage)
    car_age_lst = c(car_age_lst, paste0("CarAge_", vehage))
}

density_lst = c()
for (density in unique(quantile(training_set$Density, seq(0.01,0.99,0.01)))){
    training_set[paste0("Density_", density)] = 1*(training_set$Density <= density)
    testing_set[paste0("Density_", density)] = 1*(testing_set$Density <= density)
    density_lst = c(density_lst, paste0("Density_", density))
}

power_lst = c()
levels = levels(ordered(training_set$Power))
for (power in 1:length(unique(ordered(training_set$Power)))){
    training_set[paste0("Power_", power)] = 1*(ordered(training_set$Power) <= levels[power])
    testing_set[paste0("Power_", power)] = 1*(ordered(testing_set$Power) <= levels[power])
    power_lst = c(power_lst, paste0("Power_", power))
}

lst_vars = paste(paste(driver_age_lst, collapse=" + "), 
                 paste(car_age_lst, collapse=" + "), 
                 paste(density_lst, collapse=" + "), 
                 paste(power_lst, collapse=" + "), 
                 sep = " + ")
```

```{r}
ptn=Sys.time()
model_exp_x = model.matrix(as.formula(paste("ClaimNb ~ 0  + ", 
                                            lst_vars, 
                                            sep="")),
                           data=training_set)

head(model_exp_x)
```

```{r}
set.seed(542)
folds = createFolds(training_set$ClaimNb, 5, list=FALSE)

set.seed(58)
m.lasso.1.cv = cv.glmnet(  model_exp_x, y = training_set$ClaimNb, 
                           offset = log(training_set$Exposure),
                           family = "poisson",
                           alpha = 1, #LASSO = 1, Ridge = 0,
                           nfolds = 5,
                           foldid = folds,
                           maxit=10^4,
                           nlambda = 25)


ptn_1 = Sys.time() - ptn
ptn_1
```

```{r}
m.lasso.1.cv
```

```{r}
coef(m.lasso.1.cv, s = "lambda.min")
```

```{r}
plotdata = expand.grid(DriverAge = 18:99, 
                       CarAge = 0:25, 
                       Density = unique(quantile(training_set$Density, seq(0.01,0.99,0.01))),
                       Exposure = 1)


for (age in (18:99)){
    plotdata[paste0("DriverAge_", age)] = 1*(plotdata$DriverAge <= age)
}
for (vehage in (0:25)){
    plotdata[paste0("CarAge_", vehage)] = 1*(plotdata$CarAge <= vehage)
}
for (density in unique(sort(plotdata$Density))){
    plotdata[paste0("Density_", density)] = 1*(plotdata$Density <= density)
}

plotdata['prediction'] = predict(m.lasso.1.cv, 
                                 as.matrix(subset(plotdata, select = -c(DriverAge, CarAge,Density, Exposure))),
                                 newoffset = 0, 
                                 type="response", 
                                 s = m.lasso.1.cv$lambda.min)
```

```{r}
require(ggplot2)
ggplot(plotdata %>% group_by(DriverAge) %>% summarise(prediction = mean(prediction)), 
       aes(x=DriverAge, y=prediction)) + geom_point() + geom_line() + theme_bw() + 
        scale_y_continuous(labels = scales::label_percent(accuracy = 0.02))
```

```{r}
ggplot(plotdata %>% group_by(CarAge) %>% summarise(prediction = mean(prediction)), 
       aes(x=CarAge, y=prediction)) + geom_point() + geom_line() + theme_bw()+
scale_y_continuous(labels = scales::label_percent(accuracy = 0.02))
```

```{r}
ggplot(plotdata %>% group_by(Density) %>% summarise(prediction = mean(prediction)), 
       aes(x=Density, y=prediction)) + geom_point() + geom_line() + theme_bw()+
scale_y_continuous(labels = scales::label_percent(accuracy = 0.02))
```

```{r}
s = coef(m.lasso.1.cv, s = "lambda.min")
driver_age_breaks = c()
car_age_breaks = c()
density_breaks = c()
for (col in names(which(s[,1] != 0))){
    if (grepl("DriverAge_", col)){
         driver_age_breaks = c(driver_age_breaks, as.numeric(unlist(strsplit(col, "_"))[2]))
    }
    if (grepl("CarAge_", col)){
         car_age_breaks = c(car_age_breaks, as.numeric(unlist(strsplit(col, "_"))[2]))
    }
    if (grepl("Density_", col)){
         density_breaks = c(density_breaks, as.numeric(unlist(strsplit(col, "_"))[2]))
    }
}

# Define a data preprocessing with these breaks

data_prep = recipe(ClaimNb ~ DriverAge + CarAge + Power + Gas + Region + Brand + Density + Exposure, data = training_set) %>%
    step_relevel(Power, ref_level = "d") %>%
    step_relevel(Gas, ref_level = "Regular") %>%
    step_relevel(Region, ref_level = "Centre") %>%
    step_relevel(Brand, ref_level = "Renault, Nissan or Citroen") %>%
    step_mutate(DriverAge = cut(DriverAge, breaks = c(-Inf, driver_age_breaks, Inf))) %>%
    step_mutate(CarAge = cut(CarAge, breaks = c(-Inf, car_age_breaks, Inf))) %>%
    step_mutate(Density = cut(Density, breaks = c(-Inf, density_breaks, Inf))) %>%
    step_mutate(Power = forcats::fct_collapse(Power, 
                                                 "d-e-f" = c("d", "e", "f"),
                                                 "j-k-l-m-n-o" = c("j", "k", "l", "m", "n", "o")
                                                )) %>%
    prep()
```

```{r}
m_glm = glm(ClaimNb ~ offset(log(Exposure)) + Power + Brand + Gas + Region + DriverAge + CarAge + Density, 
   data = data_prep %>% bake(training_set),
   family=poisson(link=log))
summary(m_glm)
```

```{r}
2 * (sum(dpois(x = testing_set$ClaimNb, lambda = testing_set$ClaimNb,
    log = TRUE)) - sum(dpois(x = testing_set$ClaimNb, lambda = predict(m_glm, data_prep %>% bake(testing_set), type="response"), log=TRUE)))
```

